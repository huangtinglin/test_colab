{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMYlHqEBVHa7IkSn3/Zcmi9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/huangtinglin/test_colab/blob/main/colab0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction of PyTorch\n",
        "\n",
        "PyTorch is a free and open source framework used for machine leanring research and application. It specializes in tensor computations, automatic differentiation, and GPU acceleration. PyTorch is one of the most popular deep learning libraries. See more introduction in https://pytorch.org/. \n"
      ],
      "metadata": {
        "id": "VWhUwO_-mL2s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Outline\n",
        "\n"
      ],
      "metadata": {
        "id": "0R0-JXHoqhtD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Basic operation\n",
        "- Models\n",
        "- Datasets\n",
        "- Losses\n",
        "- Optimizers"
      ],
      "metadata": {
        "id": "ETQPVYpoqsvY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basic operation"
      ],
      "metadata": {
        "id": "zBRS0TB5mo7o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import the pytorch library into environment and check its version\n",
        "import torch\n",
        "print(\"Using torch\", torch.__version__)"
      ],
      "metadata": {
        "id": "N3aXUWpFlcnj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Tensor\n",
        "\n",
        "Tensor are the central data abstraction in PyTorch. You can generalize it to the concept you already know. For example, a vector is a 1-D tensor, and a matrix is a 2-D tensor. We can easily create a tensor of various shapes and number of dimensions by PyTorch. "
      ],
      "metadata": {
        "id": "Ei5_O8ZXtlGb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# construct a 1-D tensor from a list\n",
        "x = torch.tensor([1, 2, 3])\n",
        "print(x)\n",
        "\n",
        "# construct a 2-D tensor from a list\n",
        "x = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
        "print(x)"
      ],
      "metadata": {
        "id": "ybw_wwuStyHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given a tensor, we can obtain its shape by using `.size` or `.shape` method:"
      ],
      "metadata": {
        "id": "OCY73L2LGoS8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape of x is\", x.shape())\n",
        "\n",
        "print(\"Size of x is\", x.size())"
      ],
      "metadata": {
        "id": "HMg1NUP9Gnkq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here are alternatives to create a tensor:\n",
        "\n",
        "* `torch.zeros`: Creates a tensor filled with zeros\n",
        "* `torch.ones`: Creates a tensor filled with ones\n",
        "* `torch.rand`: Creates a tensor with random values uniformly sampled between 0 and 1\n",
        "* `torch.randn`: Creates a tensor with random values sampled from a normal distribution with mean 0 and variance 1\n",
        "* `torch.arange`: Creates a 1-D tensor containing the values $N,N+1,N+2,...,M$\n",
        "\n"
      ],
      "metadata": {
        "id": "aKHOYbMCE9b7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# construct a tensor with random numbers with shape (4, 5)\n",
        "x = torch.rand(4, 5)\n",
        "print(\"Tensor created by torch.rand function\", x)\n",
        "\n",
        "# construct a tensor filled with the scalar value 0 with shape (2, 3, 4)\n",
        "x = torch.zeros(2, 3, 4)\n",
        "print(\"Tensor created by torch.arange function\", x)"
      ],
      "metadata": {
        "id": "RfZq2L2uEphL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensor Operations\n",
        "\n",
        "PyTorch supports various tensor operations. A full list of operations can be found in the [PyTorch documentation](https://pytorch.org/docs/stable/tensors.html#). For example, we can add two tensors with same shape:"
      ],
      "metadata": {
        "id": "Sc9hyQTnIDX3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = torch.rand(2, 2)\n",
        "x2 = torch.rand(2, 2)\n",
        "x3 = x1 + x2  # return the sum of x1 and x2\n",
        "\n",
        "print(\"x1:\", x1)\n",
        "print(\"x2:\", x2)\n",
        "print(\"x3:\", x3)"
      ],
      "metadata": {
        "id": "8XSh1c4CEpst"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We also can calculate the matrix product between two tensors:"
      ],
      "metadata": {
        "id": "UMKyR-QoJiYK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(3)\n",
        "W = torch.rand(2, 3)\n",
        "h = torch.matmul(W, x)  # return the product between W and x\n",
        "\n",
        "print(\"shape of x:\", x.shape, \"x:\", x)  # shape: [3]\n",
        "print(\"shape of W:\", W.shape, \"W:\", W)  # shape: [2, 3]\n",
        "print(\"shape of h:\", h.shape, \"h:\", h)  # shape: [2]"
      ],
      "metadata": {
        "id": "Enw4SKbvKKwh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another common operation aims at changing the shape of a tensor. A tensor'size can be re-organized to any other shape with the same number of elements. In PyTorch, this operation is called `view` or `reshape`:"
      ],
      "metadata": {
        "id": "9WOoJMhaLpZU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(2, 3)\n",
        "x1 = x.view(6)\n",
        "x2 = x.reshape(3, 2)\n",
        "\n",
        "print(\"shape of x:\", x.shape, \"x:\", x)  # shape: [2, 3]\n",
        "print(\"shape of x1:\", x1.shape, \"x1:\", x1)  # shape: [6]\n",
        "print(\"shape of x2:\", x2.shape, \"x2:\", x2)  # shape: [3, 2]"
      ],
      "metadata": {
        "id": "mWT7phb4KK1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Models\n",
        "\n",
        "We can use PyTorch to build deep learning model. Here we will give an example of using multi-layer perceptron (MLP) to perform image classification. We'll start with building a MLP.\n"
      ],
      "metadata": {
        "id": "G-DjqAslNX29"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import neural network module of PyTorch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "6qFGvRYJSErW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A MLP is built by stacking multiple linear layers:\n",
        "\n",
        "$$Linear(X):=A X + b$$ \n",
        "\n",
        "with $X\\in \\mathbb{R}^{n\\times k}$, $A\\in \\mathbb{R}^{m\\times n}$, $b\\in\\mathbb{R}^{m\\times 1}$. We can implement a linear layer with `nn.Linear`:\n",
        "\n"
      ],
      "metadata": {
        "id": "WYsSkgCxSGEW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "linear = nn.Linear(5, 10)  # creat a linear layer with n=5, m=10\n",
        "\n",
        "print(linear.weight.shape)  # [10, 5]\n",
        "print(linear.bias.shape)  # [10]"
      ],
      "metadata": {
        "id": "AWhLXWFWVMQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Besides, to expand the capability and allow model to learn non-linear transformation between inputs and outputs, we will introduce the non-linear activation function between two linear layers. Here we use ReLU activation function:\n",
        "\n",
        "![](https://github.com/bentrevett/pytorch-image-classification/blob/master/assets/relu.png?raw=1)\n",
        "\n",
        "We can implement a ReLU functino by using `F.relu`:"
      ],
      "metadata": {
        "id": "P2RN7fOwV0pk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(2, 3)\n",
        "\n",
        "print(\"x:\", x)\n",
        "print(\"relu(x):\", F.relu(x))"
      ],
      "metadata": {
        "id": "56ygKD1DZajR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can try to build a MLP with linear layer and non-linear function. We use `nn.Module` to define a MLP class containing the basic modules of MLP:"
      ],
      "metadata": {
        "id": "H1ikBfJFZ1iy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        self.input_fc = nn.Linear(input_dim, 250)\n",
        "        self.hidden_fc = nn.Linear(250, 100)\n",
        "        self.output_fc = nn.Linear(100, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # x = [batch size, height, width]\n",
        "\n",
        "        batch_size = x.shape[0]\n",
        "\n",
        "        x = x.view(batch_size, -1)\n",
        "\n",
        "        # x = [batch size, height * width]\n",
        "\n",
        "        h_1 = F.relu(self.input_fc(x))\n",
        "\n",
        "        # h_1 = [batch size, 250]\n",
        "\n",
        "        h_2 = F.relu(self.hidden_fc(h_1))\n",
        "\n",
        "        # h_2 = [batch size, 100]\n",
        "\n",
        "        y_pred = self.output_fc(h_2)\n",
        "\n",
        "        # y_pred = [batch size, output dim]\n",
        "\n",
        "        return y_pred, h_2"
      ],
      "metadata": {
        "id": "_GIzPoJINXKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MLP(10, 20)"
      ],
      "metadata": {
        "id": "ukjByiB1ztz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We define a "
      ],
      "metadata": {
        "id": "IwodgWvlsmLT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1O5O2Dc1slo0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}