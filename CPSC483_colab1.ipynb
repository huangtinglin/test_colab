{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CPSC483_colab1",
      "provenance": [],
      "collapsed_sections": [
        "ddiMjUdbmW24",
        "H1ikBfJFZ1iy",
        "IEvPG5hIfuU5",
        "1SZax14Sg61s",
        "lqkSkLWKC7ku",
        "Ope6QD8w8w3S"
      ],
      "authorship_tag": "ABX9TyP9hTcrAF35FJFbAj35z0jQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/huangtinglin/test_colab/blob/main/CPSC483_colab1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Graph neural network basics\n",
        "\n",
        "In this Colab, we are going to introduce some basics of graph neural network (GNN) and build a pipeline for node classification tasks by PyTorch Geometric (PyG). See more introduction about [PyG](https://pytorch-geometric.readthedocs.io/en/latest/).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VWhUwO_-mL2s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Outline\n",
        "\n"
      ],
      "metadata": {
        "id": "0R0-JXHoqhtD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Basic operation of PyG\n",
        "- Build a GNN by PyG\n",
        "- OGB Datasets\n",
        "- Training and testing"
      ],
      "metadata": {
        "id": "ETQPVYpoqsvY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basic operation of PyG"
      ],
      "metadata": {
        "id": "zBRS0TB5mo7o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import the pytorch library into environment and check its version\n",
        "import os\n",
        "import torch\n",
        "print(\"Using torch\", torch.__version__)"
      ],
      "metadata": {
        "id": "N3aXUWpFlcnj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "521a75ae-0959-4af8-c3f3-c720b6b1c806"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using torch 1.12.1+cu113\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's start installing PyG by `pip`. The version of PyG should match the current version of PyTorch. Here we follow the [instruction](https://pytorch-geometric.readthedocs.io/en/latest/notes/installation.html) of PyG:"
      ],
      "metadata": {
        "id": "MC5DJkYNWGeL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.9.0+cu111.html\n",
        "!pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-1.9.0+cu111.html\n",
        "!pip install torch-geometric\n",
        "!pip install ogb  # for datasets"
      ],
      "metadata": {
        "id": "IeuylXONWMFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.data import Data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "id": "aR1FAZxLxcoT",
        "outputId": "d77b4b34-0b9c-42e3-944d-3793afa72683"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-b336892afbe1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mData\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_geometric/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mimportlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimport_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_geometric/data/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mData\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mhetero_data\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHeteroData\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtemporal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTemporalData\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_geometric/data/data.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_sparse\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSparseTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m from torch_geometric.data.feature_store import (\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_sparse/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mspec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcuda_spec\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcpu_spec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_library\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morigin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: no cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         raise ImportError(f\"Could not find module '{library}_cpu' in \"\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_ops.py\u001b[0m in \u001b[0;36mload_library\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0;31m# static (global) initialization code in order to register custom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0;31m# operators with the JIT.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m             \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCDLL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloaded_libraries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/ctypes/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: /usr/local/lib/python3.7/dist-packages/torch_sparse/_spmm_cuda.so: undefined symbol: _ZNK3c1010TensorImpl36is_contiguous_nondefault_policy_implENS_12MemoryFormatE"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a Graph\n",
        "\n",
        "A single graph in PyG is described by an instance of `torch_geometric.data`.Data, which holds the following attributes by default:\n",
        "\n",
        "Tensor are the central data abstraction in PyTorch. You can generalize it to the concept you already know. For example, a vector is a 1-D tensor, and a matrix is a 2-D tensor. We can easily create a tensor of various shapes and number of dimensions by PyTorch. "
      ],
      "metadata": {
        "id": "Ei5_O8ZXtlGb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# construct a 1-D tensor from a list\n",
        "x = torch.tensor([1, 2, 3])\n",
        "print(x)\n",
        "\n",
        "# construct a 2-D tensor from a list\n",
        "x = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
        "print(x)"
      ],
      "metadata": {
        "id": "ybw_wwuStyHo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efcbfefe-03a7-4ab9-ab35-c740ebefb2e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3])\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given a tensor, we can obtain its shape by using `.size` or `.shape` method:"
      ],
      "metadata": {
        "id": "OCY73L2LGoS8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape of x is\", x.shape)\n",
        "\n",
        "print(\"Size of x is\", x.size())"
      ],
      "metadata": {
        "id": "HMg1NUP9Gnkq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here are alternatives to create a tensor:\n",
        "\n",
        "* `torch.zeros`: Creates a tensor filled with zeros\n",
        "* `torch.ones`: Creates a tensor filled with ones\n",
        "* `torch.rand`: Creates a tensor with random values uniformly sampled between 0 and 1\n",
        "* `torch.randn`: Creates a tensor with random values sampled from a normal distribution with mean 0 and variance 1\n",
        "* `torch.arange`: Creates a 1-D tensor containing the values $N,N+1,N+2,...,M$\n",
        "\n"
      ],
      "metadata": {
        "id": "aKHOYbMCE9b7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# construct a tensor with random numbers with shape (4, 5)\n",
        "x = torch.rand(4, 5)\n",
        "print(\"Tensor created by torch.rand function\", x)\n",
        "\n",
        "# construct a tensor filled with the scalar value 0 with shape (2, 3, 4)\n",
        "x = torch.zeros(2, 3, 4)\n",
        "print(\"Tensor created by torch.arange function\", x)"
      ],
      "metadata": {
        "id": "RfZq2L2uEphL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensor Operations\n",
        "\n",
        "PyTorch supports various tensor operations. A full list of operations can be found in the [PyTorch documentation](https://pytorch.org/docs/stable/tensors.html#). For example, we can add two tensors with same shape:"
      ],
      "metadata": {
        "id": "Sc9hyQTnIDX3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = torch.rand(2, 2)\n",
        "x2 = torch.rand(2, 2)\n",
        "x3 = x1 + x2  # return the sum of x1 and x2\n",
        "\n",
        "print(\"x1:\", x1)\n",
        "print(\"x2:\", x2)\n",
        "print(\"x3:\", x3)"
      ],
      "metadata": {
        "id": "8XSh1c4CEpst"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We also can calculate the matrix product between two tensors:"
      ],
      "metadata": {
        "id": "UMKyR-QoJiYK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(3)\n",
        "W = torch.rand(2, 3)\n",
        "h = torch.matmul(W, x)  # return the product between W and x\n",
        "\n",
        "print(\"shape of x:\", x.shape, \"x:\", x)  # shape: [3]\n",
        "print(\"shape of W:\", W.shape, \"W:\", W)  # shape: [2, 3]\n",
        "print(\"shape of h:\", h.shape, \"h:\", h)  # shape: [2]"
      ],
      "metadata": {
        "id": "Enw4SKbvKKwh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another common operation aims at changing the shape of a tensor. A tensor'size can be re-organized to any other shape with the same number of elements. In PyTorch, this operation is called `view` or `reshape`:"
      ],
      "metadata": {
        "id": "9WOoJMhaLpZU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(2, 3)\n",
        "x1 = x.view(6)\n",
        "x2 = x.reshape(3, 2)\n",
        "\n",
        "print(\"shape of x:\", x.shape, \"x:\", x)  # shape: [2, 3]\n",
        "print(\"shape of x1:\", x1.shape, \"x1:\", x1)  # shape: [6]\n",
        "print(\"shape of x2:\", x2.shape, \"x2:\", x2)  # shape: [3, 2]"
      ],
      "metadata": {
        "id": "mWT7phb4KK1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 1 (5 points)\n",
        "\n",
        "Given a 1-D tensor, what is the index of its maximum value?\n"
      ],
      "metadata": {
        "id": "ddiMjUdbmW24"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_idx_max(x):\n",
        "  # TODO: Implement a function that takes a tensor object\n",
        "  # and returns the index of its maximum value.\n",
        "\n",
        "  max_idx = -1\n",
        "\n",
        "  ############# Your code here ############\n",
        "  ## (~1 line of code)\n",
        "\n",
        "  #########################################\n",
        "\n",
        "  return max_idx\n",
        "\n",
        "x = torch.rand(5)\n",
        "max_idx = get_idx_max(x)\n",
        "print('index of the maximum value of {} is {}'.format(x, max_idx))"
      ],
      "metadata": {
        "id": "Wg17zDRQo2HG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Models\n",
        "\n",
        "We can use PyTorch to build deep learning model. Here we will give an example of using multi-layer perceptron (MLP) to perform image classification. We'll start with building a MLP.\n"
      ],
      "metadata": {
        "id": "G-DjqAslNX29"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import neural network module of PyTorch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "6qFGvRYJSErW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A MLP is built by stacking multiple linear layers:\n",
        "\n",
        "$$Linear(X):=A X + b$$ \n",
        "\n",
        "with $X\\in \\mathbb{R}^{n\\times k}$, $A\\in \\mathbb{R}^{m\\times n}$, $b\\in\\mathbb{R}^{m\\times 1}$. We can implement a linear layer with `nn.Linear`:\n",
        "\n"
      ],
      "metadata": {
        "id": "WYsSkgCxSGEW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "linear = nn.Linear(5, 10)  # creat a linear layer with n=5, m=10\n",
        "\n",
        "print(linear.weight.shape)  # [10, 5]\n",
        "print(linear.bias.shape)  # [10]"
      ],
      "metadata": {
        "id": "AWhLXWFWVMQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can feed a tensor into the linear module to perform linear transformation:"
      ],
      "metadata": {
        "id": "ePjdm2WKb0rM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(6, 5)\n",
        "\n",
        "print(\"x:\", x)\n",
        "print(\"Linear(x):\", linear(x))"
      ],
      "metadata": {
        "id": "Kcb3PWpNcAdX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Besides, to expand the capability and allow model to learn non-linear transformation between inputs and outputs, we will introduce the non-linear activation function between two linear layers. Here we use ReLU activation function:\n",
        "\n",
        "![](https://github.com/bentrevett/pytorch-image-classification/blob/master/assets/relu.png?raw=1)\n",
        "\n",
        "We can implement a ReLU functino by using `F.relu` or `nn.ReLU()`:"
      ],
      "metadata": {
        "id": "P2RN7fOwV0pk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(2, 3)\n",
        "act_fn = nn.ReLU()\n",
        "\n",
        "print(\"x:\", x)\n",
        "print(\"F.relu(x):\", F.relu(x))\n",
        "print(\"nn.relu(x):\", act_fn(x))"
      ],
      "metadata": {
        "id": "56ygKD1DZajR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 2 (10 points)\n",
        "\n",
        "Now it is your time to build a MLP with linear layer and non-linear function. We use `nn.Module` to define a MLP class containing the basic modules of MLP. The modules we need will be defined in `__init__` function and the calculation will be performed in `forward` function."
      ],
      "metadata": {
        "id": "H1ikBfJFZ1iy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        # TODO: Define two Linear modules and a ReLU function.\n",
        "        # The input size and output size of first Linear module should be input_dim and hidden_dim\n",
        "        # The input size and output size of second Linear module should be hidden_dim and output_dim\n",
        "\n",
        "        ############# Your code here ############\n",
        "        ## (~3 line of code)\n",
        "\n",
        "        #########################################\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        batch_size = x.shape[0]\n",
        "        x = x.view(batch_size, -1)  # reshape the tensor to a 1-D vector\n",
        "\n",
        "        out = 0\n",
        "\n",
        "        # TODO: Use the modules you define in __init__ to perform calculation.\n",
        "        # ReLU function should be used in the middle of two Linear modules.\n",
        "\n",
        "        ############# Your code here ############\n",
        "        ## (~3 line of code)\n",
        "\n",
        "        #########################################\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "_GIzPoJINXKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As shown in the `MLP` class, we initialize the modules we need in `__init__` function, and perform the calculation of the model to predict the results in `forward` function. Here is an example to instantiate a MLP model:"
      ],
      "metadata": {
        "id": "vOoSsST0uMQc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = MLP(input_dim=10, hidden_dim=20, output_dim=10)\n",
        "print(model)  # show all the submodules"
      ],
      "metadata": {
        "id": "ukjByiB1ztz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can obtain the parameters of a module by its `parameters` functions, or `named_parameters` to get a name to each parameter object. For our MLP, we have the following parameters:"
      ],
      "metadata": {
        "id": "IwodgWvlsmLT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in model.named_parameters():\n",
        "    print(f\"Parameter {name}, shape {param.shape}\")"
      ],
      "metadata": {
        "id": "1O5O2Dc1slo0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Datasets\n",
        "\n",
        "We are going to use a dataset for image classification called MNIST. It is a large database of handwritten digits, and widely used for training and testing in the field of image processing. We can esily load this dataset with the help of PyTorch.\n"
      ],
      "metadata": {
        "id": "ztrLP3j8vtaR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.utils.data as data\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms"
      ],
      "metadata": {
        "id": "8gn1LsIryRDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After importing required library, we can download the dataset of MNIST and save it in a folder. It will automatically create the folder if it doesn't exist."
      ],
      "metadata": {
        "id": "s0EimIP8yZJW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ROOT = '.data'  # the folder for saving dataset\n",
        "\n",
        "train_data = datasets.MNIST(root=ROOT,\n",
        "                            train=True,\n",
        "                            download=True)"
      ],
      "metadata": {
        "id": "P9zunwfNyvK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To improve the model's generalization and robustness, we usually will preprocess and augment our dataset. Data augmentation is a group of methods for creating new data points from existing data in order to increase the amount of data. These operations are included in `transforms.Compose` function. Here are some common transforms:\n",
        "\n",
        "- `RandomRotation` - randomly rotates the image between `(-x, +x)` degrees, where we have set `x = 5`. \n",
        "- `RandomCrop` - randomly taking a square crop of the image.\n",
        "- `ToTensor()` - this converts the image from a PIL format into a PyTorch tensor.\n",
        "- `Normalize` - this subtracts the mean and divides by the standard deviations given. \n"
      ],
      "metadata": {
        "id": "t5Z8UVv_y40u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean = train_data.data.float().mean() / 255\n",
        "std = train_data.data.float().std() / 255\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "                            transforms.RandomRotation(5, fill=(0,)),\n",
        "                            transforms.RandomCrop(28, padding=2),\n",
        "                            transforms.ToTensor(),\n",
        "                            transforms.Normalize(mean=[mean], std=[std])\n",
        "                                      ])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "                           transforms.ToTensor(),\n",
        "                           transforms.Normalize(mean=[mean], std=[std])\n",
        "                                     ])"
      ],
      "metadata": {
        "id": "-23N4YwR2b4y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now with the transform function, we can load the train and test dataset of MNIST:"
      ],
      "metadata": {
        "id": "rmZBnLbt2nWc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = datasets.MNIST(root=ROOT,\n",
        "                            train=True,\n",
        "                            download=True,\n",
        "                            transform=train_transforms)\n",
        "\n",
        "test_data = datasets.MNIST(root=ROOT,\n",
        "                           train=False,\n",
        "                           download=True,\n",
        "                           transform=test_transforms)\n",
        "\n",
        "print(f'Number of training examples: {len(train_data)}')  # check the number of the image in the train datasets\n",
        "print(f'Number of testing examples: {len(test_data)}')  # check the number of the image in the test datasets"
      ],
      "metadata": {
        "id": "iBgm1GKn2jLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 3 (5 points)\n",
        "\n",
        "What is the label of the image with index 100 in the train dataset?"
      ],
      "metadata": {
        "id": "IEvPG5hIfuU5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_image_label(dataset, idx):\n",
        "  # TODO: Implement a function that takes a dataset object,\n",
        "  # an index of a image within the dataset, and returns the class/label \n",
        "  # of the image (as an integer).\n",
        "\n",
        "  label = -1\n",
        "\n",
        "  ############# Your code here ############\n",
        "  ## (~1 line of code)\n",
        "\n",
        "  #########################################\n",
        "\n",
        "  return label\n",
        "\n",
        "idx = 100\n",
        "label = get_image_label(train_data, idx)\n",
        "print('Image with index {} has label {}'.format(idx, label))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDs-UuOlf4md",
        "outputId": "02ac699b-ba2a-490a-80a2-ba9ab60457a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image with index 100 has label -1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 4 (5 points)\n",
        "\n",
        "What is the number of classes in the MNIST dataset?"
      ],
      "metadata": {
        "id": "1SZax14Sg61s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_num_classes(pyg_dataset):\n",
        "  # TODO: Implement a function that takes a dataset object\n",
        "  # and returns the number of classes for that dataset.\n",
        "\n",
        "  num_classes = 0\n",
        "\n",
        "  ############# Your code here ############\n",
        "  ## (~1 line of code)\n",
        "\n",
        "  #########################################\n",
        "\n",
        "  return num_classes\n",
        "\n",
        "num_classes = get_num_classes(train_data)\n",
        "print(\"dataset has {} classes\".format(num_classes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIaY37ozhB7C",
        "outputId": "0ab240b9-74f2-4b60-d637-39227d3e68bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset has 0 classes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can have a look at these images with the help of library `matplotlib`. "
      ],
      "metadata": {
        "id": "9Zb0ZDyp2_QX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "image_idx = 50  # the index of the image we want to see\n",
        "image = train_data[50][0]\n",
        "\n",
        "fig = plt.figure()\n",
        "plt.imshow(image.view(28, 28).cpu().numpy(), cmap='bone')  # plot the image\n",
        "plt.axis('off')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "ZZTKpDUW2kOo",
        "outputId": "b8e32323-801e-4e5a-ac3b-8b3412a7cd2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-0.5, 27.5, 27.5, -0.5)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`DataLoader` is also an important tool during our training. It can iterate over the dataset and yield a batch of images and labels to the model. The batchsize is a hyperparameter and we need to tune it during training. Here we set batchsize as 64, and define the dataloader for training and testing:"
      ],
      "metadata": {
        "id": "LJmfZ8Ll4jCi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "train_loader = data.DataLoader(train_data,\n",
        "                                 shuffle=True,  # shuffle the dataset in every epoch\n",
        "                                 batch_size=BATCH_SIZE)\n",
        "\n",
        "test_loader = data.DataLoader(test_data,\n",
        "                                batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "c0wuXZZj6FX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we need to initialize a MLP with appropriate `input_dim`, `hidden_dim` and `output_dim`. The image size is 28*28, and we will first flatten the image into a 784 element vector. So `input_dim` is 784 in MLP. `hidden_dim` is a tunable hyperparameter, and here we set it as 200. `output_dim` is the number of the classes. Please write the correct numbers and initialize a MLP:"
      ],
      "metadata": {
        "id": "E6Clt1fXZKtJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim, hidden_dim, output_dim = 0, 0, 0\n",
        "\n",
        "model = MLP(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim)"
      ],
      "metadata": {
        "id": "i4mVaLnZZlAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and testing\n",
        "\n",
        "Here is a total pipeline of training a model:\n",
        "\n",
        "- pass a batch of data through the model and obtain the prediction\n",
        "- compare the prediction with the label and calculate the loss of this batch\n",
        "- calculate the gradient of each of the parameters with respect to the loss\n",
        "- update the parameters with optimizer\n",
        "\n",
        "To end-to-end train a model, we need to define a [optimizer](https://ruder.io/optimizing-gradient-descent/) and [loss function](https://towardsdatascience.com/common-loss-functions-in-machine-learning-46af0ffc4d23). Optimizer is a kind of algorithm used to updated the parameter effectively. Here we use Adam as our optimizer:"
      ],
      "metadata": {
        "id": "P68ox-lD6yvE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())"
      ],
      "metadata": {
        "id": "j_AgDChN8pju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, we define loss function. How to choose a loss function? It depends on our current machine learning task:\n",
        "\n",
        "- Mean Square Error: measured as the average of squared difference between predictions and actual observations. It is for regression task.\n",
        "- Cross Entropy loss: computes the softmax activation function on the supplied predictions as well as the actual loss via negative log likelihood. It is for classification task. \n",
        "- Mean Absolute Error: measured as the average of sum of absolute differences between predictions and actual observations. It is for regression task.\n",
        "\n",
        "Our task is try to categorize the digit of the image, which is a kind of classification task. So here we define the Cross Entropy loss:"
      ],
      "metadata": {
        "id": "tOpgNJT59-GU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "_ylJMn0OBXVa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can start to train our model! What we will do is:\n",
        "\n",
        "- we put the model into `train` mode\n",
        "- iterate over our dataloader, returning batches of (image, label)\n",
        "- clear the gradients calculated from the last batch\n",
        "- calculate the loss between our predictions and the actual labels\n",
        "- calculate the gradients of each parameter\n",
        "- update the parameters by taking an optimizer step\n",
        "- update our metrics"
      ],
      "metadata": {
        "id": "l0y35_83BmjO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def train(model, dataloader, optimizer, loss_fn):\n",
        "\n",
        "    epoch_loss = 0\n",
        "    model.train()\n",
        "\n",
        "    for (x, y) in tqdm(dataloader, desc=\"Training\"):  # iterate over our dataloader\n",
        "\n",
        "        optimizer.zero_grad()  # clear the gradients\n",
        "\n",
        "        y_pred = model(x)\n",
        "\n",
        "        loss = loss_fn(y_pred, y)  # calculate the loss\n",
        "\n",
        "        loss.backward()  # calculate the gradients of each parameter\n",
        "        \n",
        "        optimizer.step()  # update the parameters by taking an optimizer step\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(dataloader)"
      ],
      "metadata": {
        "id": "bsKhLiOVCdow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 5 (5 points)\n",
        "\n",
        "After training the model, we need to evaluate it. Here we first need to define a function to calculate the accuracy. It will compare the model prediction against the real class label:"
      ],
      "metadata": {
        "id": "lqkSkLWKC7ku"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_accuracy(pred, label):\n",
        "  # TODO: Implement the accuracy function. This function takes the \n",
        "  # pred tensor and the label tensor. Take the index of the highest value for \n",
        "  # your prediction and compares it against the actual class label.\n",
        "\n",
        "  acc = 0.0\n",
        "\n",
        "  ############# Your code here ############\n",
        "\n",
        "  #########################################\n",
        "\n",
        "  return acc\n",
        "\n",
        "pred = torch.rand(5, 3)  # 5 examples, 3 classes\n",
        "label = torch.tensor([0, 1, 2, 1, 0])  # the true label of each example\n",
        "print(\"accuracy:\", calculate_accuracy(pred, label))"
      ],
      "metadata": {
        "id": "CopI23pyDgFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 6 (10 points)\n",
        "\n",
        "Then we define the evaluation function, which is similar as training one:\n",
        "\n",
        "- we put the model into `eval` mode\n",
        "- we wrap the iterations inside a `with torch.no_grad()`\n",
        "- iterate over our dataloader, returning batches of (image, label)\n",
        "- calculate the loss between our predictions and the actual labels\n",
        "- calculate the accuracy\n",
        "- we do not calculate or zero gradients\n",
        "- we do not take an optimizer step\n",
        "- update our metrics"
      ],
      "metadata": {
        "id": "Ope6QD8w8w3S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, dataloader, loss_fn):\n",
        "\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    # TODO: Implement a evaluation function that takes the model, \n",
        "    # dataloader, loss function and returns the average loss and accuracy.\n",
        "\n",
        "    ############# Your code here ############\n",
        "    ## (~8 lines of code)\n",
        "\n",
        "    #########################################\n",
        "\n",
        "    return epoch_loss / len(dataloader), epoch_acc / len(dataloader)"
      ],
      "metadata": {
        "id": "E_qC8okeEG8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The main difference between training process and evaluating process is:\n",
        "\n",
        "\n",
        "\n",
        "Let's start to train our model!"
      ],
      "metadata": {
        "id": "Rx4JS2VUWzOl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from time import time\n",
        "\n",
        "EPOCHS = 5  # number of training epoch\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "    start_time = time()  # record the start time\n",
        "\n",
        "    train_loss = train(model, train_loader, optimizer, loss_fn)\n",
        "\n",
        "    end_time = time()\n",
        "\n",
        "    epoch_time = end_time - start_time\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_time}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f}')\n",
        "  \n",
        "torch.save(model.state_dict(), 'model.pt')  # saving model's parameters"
      ],
      "metadata": {
        "id": "t7ghay5uYKOR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After 5 epochs' training, we can load the parameter and evaluate the model:"
      ],
      "metadata": {
        "id": "kvWnjDoRdrEK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('model.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate(model, test_loader, loss_fn)"
      ],
      "metadata": {
        "id": "UizGWUDPd4b0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "metadata": {
        "id": "fi6kkevhgR7b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}